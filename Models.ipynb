{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddb2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import metrics\n",
    "from keras.models import load_model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cecdcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/french_open_with_feature.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['diff_rank'] = df['player_0_rank'] - df['player_1_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d460ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [\n",
    " 'diff_rank',\n",
    " 'diff_match_win_percent',\n",
    " 'diff_games_win_percent',\n",
    " 'diff_5_set_match_win_percent',\n",
    " 'diff_close_sets_percent',\n",
    " 'diff_match_win_percent_clay',\n",
    " 'diff_games_win_percent_clay',\n",
    " 'diff_5_set_match_win_percent_clay',\n",
    " 'diff_close_sets_percent_clay',\n",
    " 'diff_match_win_percent_52',\n",
    " 'diff_games_win_percent_52',\n",
    " 'diff_5_set_match_win_percent_52',\n",
    " 'diff_close_sets_percent_52',\n",
    " 'diff_match_win_percent_clay_60',\n",
    " 'diff_games_win_percent_clay_60',\n",
    " 'diff_5_set_match_win_percent_clay_60',\n",
    " 'diff_close_sets_percent_clay_60',\n",
    " 'diff_match_win_percent_hh',\n",
    " 'diff_games_win_percent_hh',\n",
    " 'diff_match_win_percent_clay_hh',\n",
    " 'diff_games_win_percent_clay_hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd1297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.outcome\n",
    "features = df[features_list]\n",
    "\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea9a5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.72073, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.72073\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.72073 to 0.65424, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.65424 to 0.60815, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.60815 to 0.59499, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.59499 to 0.58855, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.58855 to 0.55918, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55918 to 0.55546, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55546 to 0.54532, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.54532 to 0.54292, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.54292\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.54292\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.54292\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.54292\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.54292\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.54292 to 0.54091, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.54091\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.54091\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.54091\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.54091\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.54091\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.54091\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.54091\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.54091\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.54091 to 0.53955, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.53955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00154: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.53955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00315: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.53955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00478: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.53955\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.53955\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(units=64, activation='relu', input_shape=(len(features.columns),)))\n",
    "network.add(layers.Dense(units=32, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=500)\n",
    "mc = ModelCheckpoint('data/best_model.h5', monitor='val_loss', mode='min', verbose=2, save_best_only=True)\n",
    "\n",
    "history = network.fit(train_features, train_target, \n",
    "            epochs=1000, verbose=0, batch_size=128, \n",
    "            validation_data=(test_features, test_target), callbacks=[es, mc]) \n",
    "\n",
    "saved_model = load_model('data/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f6ac72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.747, Test Accuracy: 0.739\n"
     ]
    }
   ],
   "source": [
    "_, train_acc = saved_model.evaluate(train_features, train_target, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(test_features, test_target, verbose=0)\n",
    "\n",
    "print('Train Accuracy: %.3f, Test Accuracy: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a5ed6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-902fe9cdc023>:9: MatplotlibDeprecationWarning: \n",
      "The 'quality' parameter of print_jpg() was deprecated in Matplotlib 3.3 and will be removed two minor releases later. Use pil_kwargs={'quality': ...} instead. If any parameter follows 'quality', they should be passed as keyword, not positionally.\n",
      "  plt.savefig('data/results/loss_acc.jpg', quality=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss after each Epoch')\n",
    "plt.plot(history.epoch[::10], history.history['loss'][::10], label='Train')\n",
    "plt.plot(history.epoch[::10], history.history['val_loss'][::10], label='Test')\n",
    "plt.legend(['Train', 'Test'],loc='upper right', title='Sample', facecolor='white',fancybox=True)\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Epochs')\n",
    "plt.savefig('data/results/loss_acc.jpg', quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56159e07",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7b00e31a33d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(test_target, saved_model.predict_classes(test_features)))\n",
    "print(confusion_matrix(test_target, saved_model.predict_classes(test_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79930c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
